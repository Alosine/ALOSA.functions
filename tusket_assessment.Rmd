---
title: "`r paste('Annual gaspereau escapement assessment for Tusket River for', format(Sys.Date(), '%Y'))`"
output: html_document
---

# Purpose

This markdown file is to have a place where we can:
- prep the data sheets pre-season
- deal with data and do plots in-season for communications
- do analysis and plots for communications post-season

Ideally, this file can be used between years without much changing, where the
year previous to the current one acts as a template. We can use the chunk option
`include=FALSE` to turn a chunk on or off so that we can run the entire file
by clicking the "Run" button at the top of the file in Rstudio.

# Set-up
```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,    # Hide code
  results = 'hide',# Hide results
  warning = FALSE, # Hide warnings
  message = FALSE  # Hide messages
)
```

```{r library_and_connection}
# Library
library(tidyverse)
library(padr) # for dates
library(ROracle)
library(imputeTS)

# Constants
#current_year <- format(Sys.Date(), "%Y")
current_year <- 2024

```

```{r source_ALOSA_functions}
# Source necessary functions from the Alosa functions
source("~/git/ALOSA.functions/functions/sourcery.R")
sourcery()
```

```{r database_connection}
channel <- dbConnect(
  DBI::dbDriver("Oracle"),
  username = "GASPEREA",
  password = "gps983",
  "PTRAN",
  believeNRows = FALSE
  )
```

# Pre-season

Only run this at the beginning of the season to generate the files we will be
filling out with data throughout the season. Set `include=TRUE` for when you
want to create sheets, other wise it should always be set to FALSE.

```{r create_data_sheets, include=FALSE}

# Creates blank data sheets for counts and biodata for Lake Vaughan
# blank.datasheets(
#   seed = 112,
#   startmonth = 3,
#   endmonth = 6,
#   startday = 1,
#   rivername = "Vaughan",
#   year = 2023,
#   recordtime = T,
#   speciesID = T,
#   strata = 6,
#   samplesperstrata = 4
# )
# 
# # Creates blank data sheets for counts and biodata for Powerhouse
# blank.datasheets(
#   seed = 113,
#   startmonth = 3,
#   endmonth = 6,
#   startday = 15,
#   rivername = "Powerhouse",
#   year = 2023,
#   recordtime = T,
#   speciesID = T,
#   strata = 6,
#   samplesperstrata = 4
# )

```

# In-season

These are the counts of gaspereau in real time that we can use for internal
communications. We may want to remove the last day if the counts for that day
are not completed in the counts file, but I have left that out for now.

```{r escapement_vd}
# Locate your CSV for counts
path_to_counts_CSV <- "R:/Science/Population Ecology Division/DFD/Alosa/Locations/Tusket River/Tusket 2024/Data Sheets/Vaughan 2024 count data.csv"

# Run escapement script
# Note: arguments year, site, and channel don't matter when database = FALSE
escapement_vd <- onespecies.river.escapement(
  path_to_counts_CSV,
  fixtime = TRUE,
  downstream.migration = FALSE,
  database = FALSE,
  year = current_year,
  site = 2,
  channel = channel
)

# We want to add where the data are from
escapement_vd$location <- "Lake Vaughan"

# Write these data to CSV so we can share them in emails
# output_folder <- "your/output/folder/goes/here"
# 
# write.csv(
#   escapement_vd,
#   file = paste0(output_folder, "/vd_in_season_summary.csv"),
#   row.names = FALSE
# )

vd <- escapement_vd %>%
    mutate(across(everything(), ~ ifelse(is.nan(.), 0, .))) %>%
    mutate(across(everything(), ~ ifelse(is.na(.), 0, .)))

vd <- vd |> mutate(date = make_date(2024, mon, day))

#in_season_vd_escapement_plot <-
vd |>
  ggplot(aes(date, total)) +
  geom_path(
    colour = "#7ECDBB",
    alpha = 0.9,
    linewidth = 1.25
    ) +
  geom_ribbon(
    aes(ymin = clow, ymax = chigh),
    fill = "#7ECDBB",
    colour = "grey90",
    alpha = 0.2
  ) +
  theme_bw() +
  labs(
    title = paste0("Gaspereau escapement for Lake Vaughan Dam for 2024"),
    x = "Date",
    y = "Fish / day"
  ) +
  scale_x_date(date_labels = "%b %d", date_breaks = "3 days") +
  scale_y_continuous(
    limits = c(0, max(vd$chigh)),
    breaks = seq(0, max(vd$chigh), by = 10000),
    labels = scales::comma
  ) +
  theme(
    axis.text.x = element_text(
      angle = 45,
      vjust = 1,
      hjust = 1
      ),
    axis.title.x = element_blank(),
    panel.grid.minor = element_blank(),
    #legend.background = element_blank(),
    plot.background = element_rect(fill = "grey95")
    )

# plot_path <- paste0(output_folder, "/in_season_vd_escapement_plot.png")
#     
#     ggsave(
#       plot_path,
#       plot = in_season_vd_escapement_plot,
#       width = 6,
#       height = 4,
#       dpi = 300
#     )
```

```{r escapement_ph}
# Locate your CSV for counts
path_to_counts_CSV <- "R:/Science/Population Ecology Division/DFD/Alosa/Locations/Tusket River/Tusket 2024/Data Sheets/Powerhouse 2024 count data.csv"

# Run escapement script
# Note: arguments year, site, and channel don't matter when database = FALSE
escapement_ph <- onespecies.river.escapement(
  path_to_counts_CSV,
  fixtime = TRUE,
  downstream.migration = FALSE,
  database = FALSE,
  year = current_year,
  site = 14,
  channel = channel
)

# We want to add where the data are from
escapement_ph$location <- "Powerhouse"

# Write these data to CSV so we can share them in emails
# output_folder <- "your/output/folder/goes/here"
# 
# write.csv(
#   escapement_ph,
#   file = paste0(output_folder, "/ph_in_season_summary.csv"),
#   row.names = FALSE
# )

ph <- escapement_ph %>%
    mutate(across(everything(), ~ ifelse(is.nan(.), 0, .))) %>%
    mutate(across(everything(), ~ ifelse(is.na(.), 0, .)))

ph <- ph |> mutate(date = make_date(2024, mon, day))

#in_season_ph_escapement_plot <-
ph |>
  ggplot(aes(date, total)) +
  geom_path(
    colour = "#7ECDBB",
    alpha = 0.9,
    linewidth = 1.25
    ) +
  geom_ribbon(
    aes(ymin = clow, ymax = chigh),
    fill = "#7ECDBB",
    colour = "grey90",
    alpha = 0.2
  ) +
  theme_bw() +
  labs(
    title = paste0("Gaspereau escapement for Powerhouse for 2024"),
    x = "Date",
    y = "Fish / day"
  ) +
  scale_x_date(date_labels = "%b %d", date_breaks = "2 days") +
  scale_y_continuous(
    limits = c(0, max(ph$chigh)),
    breaks = seq(0, max(ph$chigh), by = 1000),
    labels = scales::comma
  ) +
  theme(
    axis.text.x = element_text(
      angle = 45,
      vjust = 1,
      hjust = 1),
    axis.title.x = element_blank(),
    panel.grid.minor = element_blank(),
    #legend.background = element_blank(),
    plot.background = element_rect(fill = "grey95")
  )

# plot_path <- paste0(output_folder, "/in_season_ph_escapement_plot.png")
#     
#     ggsave(
#       plot_path,
#       plot = in_season_ph_escapement_plot,
#       width = 6,
#       height = 4,
#       dpi = 300
#     )
```

```{r compare_vd}
# Set up a function to haul data from the db for VD
get_VD_multiple_years <- function() {
  
  counts_df <- data.frame()
  
  # You can change how many years you want here
  get_years <- seq(as.integer(current_year) - 5, as.integer(current_year) - 1)
  
  for (i in get_years) {
    tryCatch({
      year_data <- onespecies.river.escapement(
        filename = "dummy_file_name",
        fixtime = TRUE,
        downstream.migration = TRUE,
        database = TRUE,
        year = i,
        site = 2,
        channel = channel
      )
      
      year_data$year <- i
      
      counts_df <- rbind(counts_df, year_data)
      
    }, error = function(e) {
      
      return(counts_df)
      
    })
    
  }
  
  return(counts_df)
  
}

multi_year_counts <- get_VD_multiple_years()

vd$year <- current_year
vd <- vd |> select(-location, -date)

multi_year_counts <- rbind(multi_year_counts, vd)

# Make sure to filter before creating dates because this screws them up ¯\_(ツ)_/¯
multi_year_counts <- multi_year_counts %>%
  mutate(across(everything(), ~ ifelse(is.nan(.), 0, .))) %>%
  mutate(across(everything(), ~ ifelse(is.na(.), 0, .)))

# You make these all have the same year in their date so they plot nicely
multi_year_counts <- multi_year_counts |>
  mutate(date = make_date(as.character(current_year), mon, day))

multi_year_counts$year <- as.character(multi_year_counts$year)

# I use the %>% pipe here to use "." to filter data ¯\_(ツ)_/¯
multi_year_counts %>%
  group_by(year) %>%
  ggplot(aes(date, total)) +
  geom_path(
    aes(colour = year),
    alpha = if_else(multi_year_counts$year != current_year, 0.3, 0.8),
    linewidth = if_else(multi_year_counts$year != current_year, 0.8, 1.2),
    na.rm = TRUE
  )+
  geom_ribbon(
    data = . %>% filter(year == 2024),
    aes(ymin = clow, ymax = chigh),
    fill = "#e76bf3",
    colour = "#e76bf3",
    alpha = 0.2
  )+
  theme_bw() +
  labs(
    title = "Gaspereau escapement for Lake Vaughan Dam for last five years",
    x = "Date",
    y = "Fish / day",
    colour = "Year",
    fill = "Year",
    linetype = "Location"
  ) +
  scale_x_date(date_labels = "%b %d", date_breaks = "1 week") +
  scale_y_continuous(
    limits = c(0, 120000),
    breaks = seq(0, 120000, by = 10000),
    labels = scales::comma
  ) + 
  theme(
    panel.grid.minor = element_blank(),
    axis.title = element_text(face = "bold"),
    axis.title.x = element_blank(),
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.background = element_blank(),
    plot.background = element_rect(fill = "grey95"),
    legend.key = element_blank()
  )

# plot_path <-
#   paste0(output_folder, "/in_season_multi_year_counts_plot.png")
# 
# ggsave(
#   plot_path,
#   plot = in_season_multi_year_counts_plot,
#   width = 6,
#   height = 4,
#   dpi = 300
# )
```

```{r vd_vs_ph}

vd$location <- "Lake Vaughan"
vd$date <- make_date(vd$year, vd$mon, vd$day)
ph$year <- current_year

counts <- rbind(vd, ph)

counts |>
  ggplot(aes(date, total)) +
  geom_path(
    data = counts |> filter(location == "Lake Vaughan"),
    aes(colour = location),
    alpha = 0.9,
    linewidth = 1.25
  ) +
  geom_ribbon(
    data = counts |> filter(location == "Lake Vaughan"),
    aes(ymin = clow,
        ymax = chigh,
        fill = location,
        colour = location),
    alpha = 0.2
  ) +
  geom_path(
    data = counts |> filter(location == "Powerhouse"),
    aes(colour = location),
    alpha = 0.9,
    linewidth = 1.25
  ) +
  geom_ribbon(
    data = counts |> filter(location == "Powerhouse"),
    aes(ymin = clow,
        ymax = chigh,
        fill = location,
        colour = location),
    alpha = 0.5
  ) +
  theme_bw() +
  labs(
    title = "Escapement estimates for gaspereau on the Tusket River",
    x = "Date",
    y = "fish / day",
    colour = "Location",
    fill = "Location"
  ) +
  scale_x_date(date_labels = "%b %d", date_breaks = "1 week") +
  scale_y_continuous(
    limits = c(0, max(counts$chigh)),
    breaks = seq(0, max(counts$chigh), by = 10000),
    labels = scales::comma
  ) +
  theme(
    axis.text.x = element_text(
      angle = 45,
      vjust = 1,
      hjust = 1
    ),
    axis.title.x = element_blank(),
    legend.position = "right",
    legend.background = element_blank(),
    panel.grid.minor = element_blank(),
    plot.background = element_rect(fill = "grey95")
    )

# plot_path <- paste0(output_folder, "/in_season_ph_vd_escapement_plot.png")
# 
# ggsave(
#   plot_path,
#   plot = in_season_ph_vd_escapement_plot,
#   width = 6,
#   height = 4,
#   dpi = 300
# )

```

```{r multi_year_ph}
ph_counts_2022 <- onespecies.partial.river.escapement(
  "R:/Science/Population Ecology Division/DFD/Alosa/Locations/Tusket River/Tusket 2022/Data Sheets/Counts/Powerhouse Count Sheet Cleaned 2022.csv",
  fixtime = FALSE,
  database = FALSE,
  2022,
  14,
  channel
  )
ph_counts_2022$year <- as.character(2022)
ph_counts_2022$location <- "Powerhouse"

ph_counts_2023 <- onespecies.river.escapement(
  "R:/Science/Population Ecology Division/DFD/Alosa/Locations/Tusket River/Tusket 2023/Data Sheets/Powerhouse 2023 count data1.csv",
  fixtime = FALSE,
  downstream.migration = FALSE,
  database = FALSE,
  2023,
  14,
  channel
  )
ph_counts_2023$year <- as.character(2023)
ph_counts_2023$location <- "Powerhouse"

# Calculate the powerhouse estimate
# Locate your CSV for counts
path_to_counts_CSV <- "R:/Science/Population Ecology Division/DFD/Alosa/Locations/Tusket River/Tusket 2024/Data Sheets/Powerhouse 2024 count data.csv"

# Run escapement script
# Note: arguments year, site, and channel don't matter when database = FALSE
escapement_ph <- onespecies.river.escapement(
  path_to_counts_CSV,
  fixtime = TRUE,
  downstream.migration = FALSE,
  database = FALSE,
  year = 2024,
  site = 14,
  channel = channel
)
escapement_ph$location <- "Powerhouse"
escapement_ph$year <- current_year

ph <- escapement_ph %>%
    mutate(across(everything(), ~ ifelse(is.nan(.), 0, .))) %>%
    mutate(across(everything(), ~ ifelse(is.na(.), 0, .)))

# Combine with counts dataframe that was previously created and which should
# have the PH counts from the in season year. This can be probably be done a
# better way, but where's the fun in that?
counts_for_multi_ph <- rbind(ph, ph_counts_2022, ph_counts_2023)
counts_for_multi_ph <- counts_for_multi_ph |> select(-location)

# Make sure to filter before creating dates because this screws them up ¯\_(ツ)_/¯
counts_for_multi_ph <- counts_for_multi_ph %>%
  mutate(across(everything(), ~ ifelse(is.nan(.), 0, .))) %>%
  mutate(across(everything(), ~ ifelse(is.na(.), 0, .)))

# You make these all have the same year in their date so they plot nicely
counts_for_multi_ph <- counts_for_multi_ph |> mutate(date = make_date(2024, mon, day))
counts_for_multi_ph$year <- as.character(counts_for_multi_ph$year)

counts_for_multi_ph %>%
  group_by(year) %>% 
  ggplot(aes(date, total)) +
  geom_path(
    aes(colour = year),
    alpha = if_else(counts_for_multi_ph$year != current_year, 0.3, 0.8),
    linewidth = if_else(counts_for_multi_ph$year != current_year, 1, 1.2),
    na.rm = TRUE
  )+
  geom_ribbon(
    data = . %>% filter(year == 2024),
    aes(ymin = clow, ymax = chigh),
    fill = "#7eadfc",
    colour = "#7eadfc",
    alpha = 0.2
  )+
  theme_bw() +
  labs(
    title = "Gaspereau escapement for the Powerhouse",
    x = "Date",
    y = "Fish / day",
    colour = "Year"
  ) +
  scale_x_date(date_labels = "%b %d", date_breaks = "3 days") +
  scale_y_continuous(
    limits = c(0, max(counts_for_multi_ph$chigh)),
    breaks = seq(0, max(counts_for_multi_ph$chigh), by = 1000),
    labels = scales::comma
  ) +
  theme(
    panel.grid.minor = element_blank(),
    axis.title = element_text(face = "bold"),
    axis.title.x = element_blank(),
    axis.text.x = element_text(angle = 45, hjust = 1),
    plot.background = element_rect(fill = "grey95"),
    legend.background = element_blank(),
    legend.key = element_blank()
  )

```

# Post-season

The analyses here can only be done after uploading the data from the year to the
database. Read the `Writing Annual Data to Oracle.R` script in the `Alosa.functions`
folder to see the protocol for uploading data. There are methods in that script
to prevent errors, check the data, etc.

Since we only have info about species distributions at the Lake Vaughan ladder,
I have written the following code to use our observations there to calculate 
proportions for bluebacks. These proportions will be used to estimate the catch
that can be considered bluebacks as well. You could change this code to include
the powerhouse data easily by adding it to the `counts` data frame produced
below by running `onespecies.river.escapement` on your Powerhouse data and then
using `rbind` to add it to the counts data frame.

## Species proportions VD
```{r species}
# Get the counts for the year for Lake Vaughan
path_to_counts_CSV <- "R:/Science/Population Ecology Division/DFD/Alosa/Locations/Tusket River/Tusket 2024/Data Sheets/Vaughan 2024 count data.csv"

counts <- onespecies.river.escapement(
  path_to_counts_CSV,
  fixtime = TRUE,
  downstream.migration = FALSE,
  database = FALSE,
  year = current_year,
  site = 2,
  channel = channel
)

counts <- counts %>%
    mutate(across(everything(), ~ ifelse(is.nan(.), 0, .))) %>%
    mutate(across(everything(), ~ ifelse(is.na(.), 0, .)))

counts <- counts |> mutate(date = make_date(2024, mon, day))

counts$year <- current_year

# This calculates the proportions of alewives and BBs in the escapement estimates
# based on the biodata where we took information on species proportions.
proportions <- split_species(
    year = current_year,
    siteID = 2,
    channel = channel
  )

counts_species <- counts |>
      mutate(date = make_date(year, mon, day)) |>
      ungroup() |>
      select(date, total, clow, chigh) |>
      inner_join(proportions, by = "date") |>
      mutate(B = total * BBprop, A = total - B) |>
      select(date, A, B) |>
      pivot_longer(cols = c(A, B),
                   names_to = "species",
                   values_to = "total") |>
      mutate(species = str_replace(species, "A", "Alewives")) |>
      mutate(species = str_replace(species, "B", "Bluebacks")) |>
      ungroup()

# This plot will show where the gaps are in sampling days - the GLM plots in the
# future chunks will fill these in, but this plot is just to help visualize our
# situation.
counts_species |>
  group_by(species) |>
  ggplot(aes(date, total)) +
  geom_path(aes(colour = species), size = 1) +
  geom_point(aes(fill = species), shape = 21, colour = "black", size = 2)+
  theme_bw() +
  labs(
    title = paste0(
      "Escapement estimates for gaspereau by species for ",
      current_year
    ),
    y = "Fish / day",
    colour = "Species",
    fill = "Species"
  ) +
  scale_x_date(date_labels = "%b %d", date_breaks = "3 days") +
  scale_y_continuous(
    limits = c(0, max(counts_species$total, na.rm = TRUE)),
    breaks = seq(0, max(counts_species$total, na.rm = TRUE), by = 10000),
    labels = scales::comma
  ) +
  theme(
    axis.text.x = element_text(
      angle = 45,
      vjust = 1,
      hjust = 1
      ),
    plot.background = element_rect(fill = "grey95"),
    legend.background = element_blank(),
    legend.key = element_blank(),
    axis.title.x = element_blank(),
    panel.grid.minor = element_blank()
  )

```

## Species proportions GLM
```{r GLM_approach}
# We often have days that we could not sample biodata for various reasons. We
# can use padr::pad to identify which dates are missing and then fill with NAs.
pp <- padr::pad(proportions, interval = "day")

# To prevent trouble down the road, we create a column to store the "date" as 
# an integer value. When date is used in the model, it really doesn't have to be
# a date, it just has to be an integer. As dates can cause headaches with many
# functions etc. it is safe to use an integer instead.
pp$day_int <- 1:nrow(pp)

# We use a Poisson GLM as we are dealing with count data. This model is imperfect
# and we know this, but for our current requirements, it is fairly useful. We
# wouldn't want to use this model to extrapolate very far out. We train the model
# on the complete data set.
model <- glm(BB ~ day_int, data = pp, offset = log(total_fish), family = "poisson")

# We set the total_fish to 1 so that we get proportions when we predict the new
# data. We usually try to get 100 fish sampled per day in the biodata, but that
# doesn't always happen, especially at the tails of the season.
out <- data.frame(day_int = 1:nrow(pp), total_fish = rep(1,nrow(pp)))
out.pred <- predict(model, newdata = out, type = "link", se.fit = T)

# This is the inverse of the link function i.e. the inverse of the log i.e exp
ginv <- model$family$linkinv

# We use the inverse of the link function to calculate the expected proportion.
# Note, this is the same as doing exp(out.pred[[1]])
out.pred <- ginv(out.pred[[1]])

# Create a new column for the new predicted proportions of BBs
pp$BBpropnew<-NA

# Populate the dataframe with the predicted values
for(i in 1:nrow(pp)) {
  if (is.na(pp$BBprop[i]) == T) {
    pp$BBpropnew[i] <- out.pred[i]
    pp$BBprop[i] <- out.pred[i]
  }
}

# We can flag which data were observed and which were modeled
pp$observation <- is.na(pp$total_fish)
pp <- pp |> mutate(observation = if_else(observation == TRUE, "Modeled", "Observed"))

# Check the plot
pp |> 
  ggplot(aes(date, BBprop))+
  geom_path(colour = "grey50", linewidth = 0.5, linetype = "dashed")+
  geom_point(aes(fill = observation), shape = 21, colour = "black", size = 2)+
  theme_bw()+
  labs(
    title = "Proportion of blueback herring in biodata with values for missing dates from GLM",
    y = "Proportion of fish",
    fill = "Estimate"
  ) +
  scale_x_date(date_labels = "%b %d", date_breaks = "1 week") +
  scale_y_continuous(
    limits = c(0, 1),
    breaks = seq(0, 1, by = .1),
    labels = scales::comma
  ) +
  theme(
    axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
    plot.background = element_rect(fill = "grey95"),
    axis.title.x = element_blank(),
    legend.background = element_blank(),
    legend.key = element_blank()
  )

```

## Species escapement VD
```{r blueback_escapement_vd}
# Combine the Lake Vaughan escapement estimates with the proportions dataframe
# where we calculated the proportions of bluebacks for each date
result <- left_join(pp, counts, by = "date")
result <- result |> 
  select(date, BBprop, total) |> 
  mutate(
    BB = BBprop * total,
    A = total - BB
    ) |>
  select(-BBprop, -total) |> 
  pivot_longer(
    cols = c(A, BB),
    names_to = "Species",
    values_to = "Total"
    )

result |> 
  ggplot(aes(date, Total))+
  geom_path(aes(colour = Species), size = 1)+
  geom_point(aes(fill = Species), shape = 21, colour = "black", size = 2)+
  theme_bw()+
  labs(
    title = "Estimated escapement for alewives and bluebacks at Lake Vaughan for 2024",
    y = "Fish / day"
  ) +
  scale_x_date(date_labels = "%b %d", date_breaks = "1 week") +
  scale_y_continuous(
    limits = c(0, max(result$Total)),
    breaks = seq(0, max(result$Total), by = 10000),
    labels = scales::comma
  ) +
  theme(
    axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
    plot.background = element_rect(fill = "grey95"),
    axis.title.x = element_blank(),
    legend.background = element_blank(),
    legend.key = element_blank()
  )

```

## Total counts VD + PH
```{r total_counts}
# I use the CSVs for counts here because I can only get 2024 data to run from
# the database without throwing an error, 2022 and 2023 do not work
path_to_counts_CSV <- "R:/Science/Population Ecology Division/DFD/Alosa/Locations/Tusket River/Tusket 2024/Data Sheets/Vaughan 2024 count data.csv"

vd_split <- split_species(
  year = current_year,
  siteID = 2,
  channel = channel,
  biodata_CSV = NULL
  )

counts_vd <- twospecies.river.escapement(
  path_to_counts_CSV,
  fixtime = TRUE,
  downstream.migration = FALSE,
  database = FALSE,
  year = current_year,
  site = 2,
  channel = channel,
  species.split = vd_split
)

# Got to grab each of the lists within counts_vd which get created by 
# twospecies.river.escapement and then add a column to each indicating which
# species they represent (A = Alewives, B = Bluebacks)
vd_alewives <- as_tibble(counts_vd[[1]])
vd_alewives$species = "A"

vd_bluebacks <- as_tibble(counts_vd[[2]])
vd_bluebacks$species = "B"

counts_vd <- rbind(vd_alewives, vd_bluebacks)
counts_vd$location <- "Lake Vaughan"

# We use the split for Vaughan Dam here because there are no counts made at PH
path_to_counts_CSV <- "R:/Science/Population Ecology Division/DFD/Alosa/Locations/Tusket River/Tusket 2024/Data Sheets/Powerhouse 2024 count data.csv"

counts_ph <- twospecies.river.escapement(
  path_to_counts_CSV,
  fixtime = TRUE,
  downstream.migration = FALSE,
  database = FALSE,
  year = current_year,
  site = 14,
  channel = channel,
  species.split = vd_split
)

ph_alewives <- as_tibble(counts_ph[[1]])
ph_alewives$species = "A"

ph_bluebacks <- as_tibble(counts_ph[[2]])
ph_bluebacks$species = "B"

counts_ph <- rbind(ph_alewives, ph_bluebacks)
counts_ph$location <- "Powerhouse"

# Join these counts into a single dataframe so we can add them
counts_joined <- rbind(counts_vd, counts_ph)

counts <- counts_joined %>%
  mutate(
    across(
      everything(), ~ replace_na(., 0)
      )
    )

# Convert species counts to a format that we can easily copy into the 
# "daily_counts_all_years_all_rivers.csv" file for the plots in the 
# Tusket River Annual Summary Document.
counts_for_csv <- counts |>
  group_by(species) |>
  summarise(total_escapement = sum(total))

counts_for_csv <- counts_for_csv |> 
  bind_rows(
    counts_for_csv |>
      summarise(total_escapement = sum(total_escapement)) |> 
      mutate(species = "All")
  )

```

## Species catch

These numbers are required for the `Tusket River Annual Summary` document that is
made every year. They are estimates of the number of bluebacks caught in the Tusket.
The numbers here are used to fill in data in `river summaries all years.csv` that
from which `Tusket River Annual Summary Document_Script.Rmd` pulls its data when writing
the document.

```{r catch_data}
inspection <- readxl::read_xlsx(
  "R:/Science/Population Ecology Division/DFD/Alosa/Locations/Tusket River/Tusket 2022/Data Sheets/2022 Yarmouth County Catch Inspection.xlsx",
  sheet = "Sheet1"
  )

inspection <- inspection |> mutate(date = make_date(year = year, month = mon, day = day))
may_13_2022_prop <- inspection |> 
  filter(date >= "2022-05-13" & date <= "2022-05-15" & method == "gill" & river == "Tusket") |> 
  summarize(BBprop = sum(n.blueback) / sum(n.alewife))

may_20_2022_prop <- inspection |> 
  filter(date >= "2022-05-20" & date <= "2022-05-22" & method == "gill" & river == "Tusket") |> 
  summarize(BBprop = sum(n.blueback) / sum(n.alewife))

```

```{r blueback_catch}
# I THINK I NEED TO REDO THIS WHOLE SECTION AND USE OFFSETS OF 7 AND 3 DAYS LIKE 
# I HAVE DONE FOR OTHER ANALYSES
# 
# HOW MANY WEEKS SHOULD WE CONSIDER THE DIPPERS AS HAVING ACCESS TO BB?
# 
# 
# 
# This section will need to be edited for each year. The way this is currently
# set up requires you to identify which of the last weeks of May you want to
# calculate blueback catch for. This will be based on when bluebacks were
# detected. In the example below, we only used gill net data as there were no
# bluebacks found at the dipping stands when George and Mark sampled their
# catches in 2022.
load("C:/Users/graylo/Documents/data/marfis_pull.Rdata")
source("R:/Science/Population Ecology Division/DFD/Alosa/MARFISSCI/MARFIS.error.cleaner.R")
catch <- convert.KGS(catch)

# Total tusket catch
tusket_total_catch <- catch |>
  filter(YEAR == 2024 & RIVERNAME_CLEANED == "TUSKET") |> 
  # We divide by the conversion factor to convert mass to count
  summarise(total_catch = sum(KGS) / .240)

# I checked the logbooks for the Tusket licences from the filtered data above, and they all look good for 2024. There were a few small mistakes that I won't correct here.
tusket_gill <- catch |>
  filter(YEAR == 2024 & RIVERNAME_CLEANED == "TUSKET" & GEAR_DESCRIPTION == "GILL NET (SET OR FIXED)")

# Now for the dippers
tusket_gill <- catch |>
  filter(YEAR == 2024 & RIVERNAME_CLEANED == "TUSKET" & GEAR_DESCRIPTION == "GILL NET (SET OR FIXED)")

tusket_gill <- as_tibble(tusket_gill)

# Get landings per week for last two weeks for gill netters only
week_1 <- tusket_gill |> filter(FV_DATE_FISHED >= "2024-05-17" & FV_DATE_FISHED <= "2024-05-20") |> summarise(total_kg = sum(KGS))
week_2 <- tusket_gill |> filter(FV_DATE_FISHED >= "2024-05-24") |> summarise(total_kg = sum(KGS))

# Convert landings to individual fish using 0.240 kilograms per fish 
# (i.e. a fish has a mass of 240 g) and make tibble of all estimates
bb_catch <- tibble(
  week1 = round(week_1$total_kg * may_13_2022_prop$BBprop / .240),
  week2 = round(week_2$total_kg * may_20_2022_prop$BBprop / .240)
  )

bb_catch <- bb_catch |> mutate(total_bb_catch = rowSums(across(everything())))

bb_catch <- bb_catch$total_bb_catch
```

```{r blueback_exploitation}
pp$date <- ymd(pp$date)
counts <- counts |> mutate(date = make_date(year = year, month = mon, day = day))
result <- left_join(pp, counts, by = "date")

result <- result |> 
  select(date, BBprop, total) |> 
  mutate(
    BB = BBprop * total,
    A = total - BB
  ) |>
  select(-BBprop, -total) |> 
  pivot_longer(
    cols = c(A, BB),
    names_to = "Species",
    values_to = "Total"
  )

bb_total <- result |> 
  group_by(Species) |> 
  summarise(sum = sum(Total))

# Exploitation rate
bb_exploitation <- bb_catch / (bb_total$sum[2] + bb_catch)
```

```{r summary_table}
# Label counts from Lake Vaughan
counts$location <- "Lake Vaughan"
counts <- counts |> select(total, location)
total_count_vd <- sum(counts$total)

# PH counts
ph_counts <- onespecies.river.escapement(
  fixtime = FALSE,
  downstream.migration = FALSE,
  database = TRUE,
  year = current_year,
  site = 14,
  channel = channel
)
ph_counts$location <- "Powerhouse"
ph_counts <- ph_counts |> select(total, location)
total_count_ph <- sum(ph_counts$total)

# Combine counts from both sites
counts <- rbind(counts, ph_counts)
total_count <- sum(counts$total)

df <- tibble(
  tusket_escapement = total_count,
  VD_escapement = total_count_vd,
  PH_escapement = total_count_ph,
  VD_bb_escapement = bb_total$sum[2],
  tusket_catch = round(tusket_total_catch$total_catch),
  tusket_catch_bb = bb_catch
)

df <- df |> pivot_longer(cols = everything(), names_to = "variable", values_to = "count")
df <- df |> mutate(count = round(count))
df <- df |> mutate(count = scales::comma(count))
```

```{r summary_table2, results='asis'}
library(gt)

gt_table <-
  df |> 
  gt() |> 
  tab_header(title = "Season summary") |>
  cols_label(
    variable = "Observation",
    count = "Count"
  )

gt_table
```

